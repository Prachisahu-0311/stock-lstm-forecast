# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ycRHtcGsAR44JTKrK9qTvmLO99FcQ1pe
"""

import streamlit as st
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

import torch
import torch.nn as nn

# -------------------
# LSTM Model Definition
# -------------------
class LSTMForecaster(nn.Module):
    def __init__(self, n_features, hidden_size=64, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=n_features,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True
        )
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]      # last timestep
        out = self.fc(out)
        return out


def create_sequences(features, target, seq_len):
    X, y = [], []
    for i in range(len(features) - seq_len):
        X.append(features[i:i+seq_len])
        y.append(target[i+seq_len])
    return np.array(X), np.array(y)

# -------------------
# Main Streamlit App
# -------------------
def main():
    st.title("ðŸ“ˆ Stock Price Forecasting (LSTM-based)")
    st.write(
        "This app trains an LSTM model on historical stock data with technical indicators "
        "and forecasts the closing price on the last test window."
    )

    # Sidebar inputs
    st.sidebar.header("Configuration")
    ticker = st.sidebar.text_input("Stock Ticker", value="AAPL")
    start_date = st.sidebar.date_input("Start Date", value=pd.to_datetime("2015-01-01"))
    end_date = st.sidebar.date_input("End Date", value=pd.to_datetime("today"))
    seq_len = st.sidebar.slider("Lookback Window (days)", 20, 60, 30)
    test_size = st.sidebar.slider("Test Size (days)", 60, 300, 200)
    epochs = st.sidebar.slider("Training Epochs", 5, 40, 20, step=5)

    if st.sidebar.button("Run Forecast"):
        with st.spinner("Downloading data & training model..."):
            # 1. Download data
            data = yf.download(ticker, start=start_date, end=end_date)

            if data.empty:
                st.error("No data downloaded. Check ticker or date range.")
                return

            # Handle MultiIndex columns if present
            if isinstance(data.columns, pd.MultiIndex):
                data.columns = [c[0] for c in data.columns]

            df = data.copy()

            # 2. Feature Engineering
            df['Return'] = df['Close'].pct_change()
            df['SMA_10'] = df['Close'].rolling(10).mean()
            df['SMA_30'] = df['Close'].rolling(30).mean()
            df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()
            df['EMA_30'] = df['Close'].ewm(span=30, adjust=False).mean()
            df['Volatility_10'] = df['Return'].rolling(10).std()

            # RSI
            delta = df['Close'].diff()
            gain = delta.where(delta > 0, 0.0)
            loss = -delta.where(delta < 0, 0.0)
            avg_gain = gain.rolling(14).mean()
            avg_loss = loss.rolling(14).mean()
            rs = avg_gain / (avg_loss + 1e-9)
            df['RSI_14'] = 100 - (100 / (1 + rs))

            df = df.dropna()

            if len(df) <= test_size + seq_len + 5:
                st.error("Not enough data after feature engineering. Try reducing test size or changing dates.")
                return

            st.subheader("Sample of Engineered Data")
            st.write(df.tail())

            # 3. Prepare data for LSTM
            feature_cols = [
                'Close', 'Return', 'SMA_10', 'SMA_30',
                'EMA_10', 'EMA_30', 'Volatility_10', 'RSI_14', 'Volume'
            ]
            df_model = df[feature_cols].copy()

            feature_scaler = MinMaxScaler()
            target_scaler = MinMaxScaler()

            features_scaled = feature_scaler.fit_transform(df_model.values)
            target_scaled = target_scaler.fit_transform(df[['Close']].loc[df_model.index].values)

            X_all, y_all = create_sequences(features_scaled, target_scaled, seq_len)

            # Train/Test split
            X_train, X_test = X_all[:-test_size], X_all[-test_size:]
            y_train, y_test = y_all[:-test_size], y_all[-test_size:]

            device = torch.device("cpu")
            X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)
            y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)
            X_test_t  = torch.tensor(X_test, dtype=torch.float32).to(device)
            y_test_t  = torch.tensor(y_test, dtype=torch.float32).to(device)

            # 4. Define & Train LSTM
            n_features = X_train.shape[2]
            model = LSTMForecaster(n_features=n_features, hidden_size=64, num_layers=2).to(device)
            criterion = nn.MSELoss()
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

            n = X_train_t.shape[0]
            batch_size = 64

            for epoch in range(1, epochs + 1):
                model.train()
                perm = torch.randperm(n)
                epoch_loss = 0.0

                for i in range(0, n, batch_size):
                    idx = perm[i:i+batch_size]
                    xb = X_train_t[idx]
                    yb = y_train_t[idx]

                    optimizer.zero_grad()
                    preds = model(xb)
                    loss = criterion(preds, yb)
                    loss.backward()
                    optimizer.step()
                    epoch_loss += loss.item() * xb.size(0)

                epoch_loss /= n
                if epoch % 5 == 0 or epoch == 1:
                    st.write(f"Epoch {epoch}/{epochs} - Loss: {epoch_loss:.6f}")

            # 5. Evaluation
            model.eval()
            with torch.no_grad():
                y_pred_test = model(X_test_t).cpu().numpy()

            y_test_inv = target_scaler.inverse_transform(y_test)
            y_pred_inv = target_scaler.inverse_transform(y_pred_test)

            y_test_inv = y_test_inv.flatten()
            y_pred_inv = y_pred_inv.flatten()

            rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))
            mae = mean_absolute_error(y_test_inv, y_pred_inv)
            mape = np.mean(np.abs((y_test_inv - y_pred_inv) / y_test_inv)) * 100

            st.subheader("ðŸ“Š LSTM Performance (Test Set)")
            st.write(f"**RMSE:** {rmse:.2f}")
            st.write(f"**MAE :** {mae:.2f}")
            st.write(f"**MAPE:** {mape:.2f}%")

            # 6. Plot Actual vs Predicted
            idx = df_model.index[-test_size:]

            fig, ax = plt.subplots(figsize=(12, 5))
            ax.plot(idx, y_test_inv, label="Actual", color="black")
            ax.plot(idx, y_pred_inv, label="LSTM Forecast", color="orange")
            ax.set_title(f"{ticker} â€“ Actual vs LSTM Forecast (Last {test_size} days)")
            ax.set_xlabel("Date")
            ax.set_ylabel("Price")
            ax.legend()
            st.pyplot(fig)

            st.success("Done! Model trained & forecast generated.")

if __name__ == "__main__":
    main()